   TAC 2013 KBP English Regular Slot Filling Assessment Results V1.1
                              LDC2013E91

                           October 2, 2013
                      Linguistic Data Consortium    

0.1 Update

V1.0 of this package contained an error in which 6 responses, assessed
as either correct or redundant (Columns 1 and 2 for each are listed
below), were missing coreference information.  This update corrects
the error.

5	SF13_ENG_017:per:title	
75	SF13_ENG_017:per:title	
180	SF13_ENG_017:per:title	
162	SF13_ENG_017:per:title	
132     SF13_ENG_028:per:title  
16	SF13_ENG_042:per:charges

1. Introduction

Text Analysis Conference (TAC) is a series of workshops organized by
the National Institute of Standards and Technology (NIST).  TAC was
developed to encourage research in natural language processing (NLP)
and related applications by providing a large test collection, common
evaluation procedures, and a forum for researchers to share their
results.  Through its various evaluations, the Knowledge Base
Population (KBP) track of TAC encourages the development of systems
that can match entities mentioned in natural texts with those
appearing in a knowledge base and extract novel information about
entities from a document collection and add it to a new or existing
knowledge base.

The regular English Slot Filling task (SF) involves mining information
about entities from text. SF can be viewed as more traditional
Information Extraction, or alternatively, as a Question Answering (QA)
task, in which the questions are static but the targets change. In
completing the task, participating systems and LDC annotators search a
corpus for information about person (PER) and organization (ORG)
entities and add any new information they uncover to an existing
knowledge base (KB). In English SF 2013, valid, returnable information
about entities is categorized into forty-one "slots", or
attributes. For more information about English SF, please refer to the
track home page at http://surdeanu.info/kbp2013/

This package contains results for the assessment of responses produced
during the TAC 2013 KBP English Regular Slot Filling task.


2. Contents

./README.txt

  This file.

./data/*

  The data directory holds 1940 assessment files, the combination of
  which contains a total of 27,655 assessed responses. Assessment was
  performed on a set of pooled responses provided by NIST that
  includes fillers and justification returned by both systems and LDC
  annotators.
 
  There is one file for each combination of query entity and slot for
  the queries found in TAC 2013 KBP English Regular Slot Filling
  Evaluation Queries and Annotations V1.1 (LDC2013E77). The only
  exception is that, if a given slot was included in the ignore
  element for a given query, there is no file for that query/slot
  pair. In the event that there were no fillers to assess for a
  query/slot combination that was not included in the ignore element
  of the queries file, there is an empty file in the data directory to
  represent the pair.

  The assessment results files contain 12 tab-delimited fields. The field
  definitions are as follows:

    Column 1: Response number [generated by NIST]

    Column 2: SF query ID + slot name

    Column 3: A single doc ID for a document in the source corpus
              (LDC2013E45) that was identified as supporting the
              relation between the query entity and the slot filler
              [from submission Column 4]

    Column 4: A slot filler (possibly normalized, e.g., for dates;
              otherwise, should appear in the provenance document)
              [from submission Column 5]

    Column 5: Start-end character offsets for representative mentions
              used to extract/normalize filler. If two strings were
              used, they are represented as two, comma-separated
              offset pairs [from submission Column 6]

    Column 6: Start-end character offsets for representative mentions
              used to extract/normalize query entity. If two strings
              were used, they are represented as two, comma-separated
              offset pairs [from submission Column 7]

    Column 7: Start-end character offsets of clause(s)/sentence(s) in
              justification. If two strings were used, they are
              represented as two, comma-separated offset pairs [from
              submission Column 8]

    Column 8: LDC Assessment of Col 5 (filler offsets):

                C - Correct 
                W - Wrong
                X - Inexact 
                I - Ignore

    Column 9: LDC Assessment of Col 6 (query entity offsets):

                C - Correct 
                W - Wrong
                X - Inexact 
                I - Ignore
                0 - No Response (for {per,org}:alternate_names only)

    Coumn 10: LDC Assessment of Col 7 (relation justification offsets):

                C - Correct 
                W - Wrong
                L - Inexact-Long
                S - Inexact-Short 
                I - Ignore
                0 - No Response (for {per,org}:alternate_names only)

    Column 11: LDC Assessment of Col 4 (slot filler value
               correctness), with respect to the justification region
               defined by Cols 5-7:

                C - Correct 
                W - Wrong
                X - Inexact
                R - Redundant 
                I - Ignore

    Column 12: LDC Equivalence class of Col 4 (slot filler) if Col 11
               is Correct or Redundant

./docs/TAC_KBP_2013_Assessment_Guidelines_V1.3.pdf

  The most current version of the assessment guidelines. In
  conjunction with TAC_KBP_2013_Slot_Descriptions, these guidelines
  were used by assessors to judge the validity of responses produced
  during the 2013 English regular Slot Filling evaluation

./docs/TAC_KBP_2013_Slot_Descriptions.pdf

  The most current version of the TAC KBP slot definitions. During
  Slot Filling annotation and assessment, these guidelines are used by
  annotators to judge the validity of potential and provided fillers
  for each slot.

./docs/files.md5

  This file contains md5 hashes of the files in the package. On
  Unix-like systems, the following command can be used to verify the
  integrity of the data files:

    md5sum -c docs/files.md5


3. Copyright Information

(c) 2013 Trustees of the University of Pennsylvania


4. Contact Information

For further information about this data release, or the TAC 2013 KBP
project, contact the following project staff at LDC:

    Joe Ellis, Project Manager           <joellis@ldc.upenn.edu>
    Jeremy Getman, Lead Annotator        <jgetman@ldc.upenn.edu>
    Kate Peterson, Lead Corpus Developer <petka@ldc.upenn.edu>
    Stephanie Strassel, Consultant       <strassel@ldc.upenn.edu> 

--------------------------------------------------------------------------
README created by Joe Ellis on September 18, 2013
       updated by Joe Ellis on September 20, 2013
       updated by Joe Ellis on October 2, 2013
