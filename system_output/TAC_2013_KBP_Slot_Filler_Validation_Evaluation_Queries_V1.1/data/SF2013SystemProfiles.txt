TeamID	RunNumber	Web Use?	2009 Rank	2010 Rank	2011 Rank	2012 Rank	Extract from KBP 2013 Source Corpus?	Confidence Value has Meaning?	Confidence Value is a Probability?	Query Expansion	Document Retrieval	Sentence Retrieval	NER	Nominal Tagging	Coreference Resolution	Third-party Relation/Event Extraction	Dependency Parsing	POS Tagging	Chunking	Constituent Parsing	Main Slot-filling Algorithm	Learning Approach	Learning Algorithm	Ensemble Model	External Resources	"Other salient features"

SFV2013_01	1	No	NA	NA	NA	NA	Yes	Yes	No	NA	Solr	NA	Stanford	ClearNLP	Stanford	ClearNLP	ClearNLP	ClearNLP	NA	NA	OpenIE	Bootstrapping	NA	NA	"Freebase, Crosswikis, NELL, TipsterGazetteer"	"We processed the KBP corpus with our Open IE system, producing tuples of the form (arg1, rel, arg2), then manually developed rules to map KBP relations to Open IE tuples. This run used rules that were refined over two weeks using the KBP 2012 benchmark, and used coreference to expand the set of results."
SFV2013_01	2	No	NA	NA	NA	NA	Yes	Yes	No	NA	Solr	NA	Stanford	ClearNLP	Stanford	ClearNLP	ClearNLP	ClearNLP	NA	NA	OpenIE	Bootstrapping	NA	NA	"Freebase, Crosswikis, NELL, TipsterGazetteer"	"We processed the KBP corpus with our Open IE system, producing tuples of the form (arg1, rel, arg2), then manually developed rules to map KBP relations to Open IE tuples. This run used rules that were refined over two weeks using the KBP 2012 benchmark, but does not use coreference."
SFV2013_01	3	No	NA	NA	NA	NA	Yes	Yes	No	NA	Solr	NA	Stanford	ClearNLP	Stanford	ClearNLP	ClearNLP	ClearNLP	NA	NA	OpenIE	Bootstrapping	NA	NA	"Freebase, Crosswikis, NELL, TipsterGazetteer"	"We processed the KBP corpus with our Open IE system, producing tuples of the form (arg1, rel, arg2), then manually developed rules to map KBP relations to Open IE tuples. This run used rules that were created in three hours, and includes coreference."
SFV2013_02	1	No	NA	NA	NA	NA	Yes	Yes	Yes	Wikipedia	Lucene	InHouse	Stanford	NA	NA	NA	Stanford	Stanford	NA	NA	Patterns	NA	NA	NA	InHouseDictionary	"The origin dependency patterns were created through automatic and manual ways. And then list of synonyms were used to extend the trigger keywords, increasing the number of dependency patterns to 20,494. This run only used the dependency patterns to extract slot fillers while the other four runs combined the dependency patterns and supervised learning approach."
SFV2013_02	2	No	NA	NA	NA	NA	Yes	Yes	Yes	Wikipedia	Lucene	InHouse	Stanford	NA	NA	NA	Stanford	Stanford	NA	NA	Patterns	Supervised	NA	NA	InHouseDictionary	"The origin dependency patterns were created through automatic and manual ways. And then list of synonyms were used to extend the trigger keywords, increasing the number of dependency patterns to 20,494. This run combined the dependency patterns and supervised learning approach while Run1 only used the dependency patterns. The only difference between the latter four runs (Run 2,3,4 and 5) is the threshold for filtering the candidate slot fillers."
SFV2013_02	3	No	NA	NA	NA	NA	Yes	Yes	Yes	Wikipedia	Lucene	InHouse	Stanford	NA	NA	NA	Stanford	Stanford	NA	NA	Patterns	Supervised	NA	NA	InHouseDictionary	"The origin dependency patterns were created through automatic and manual ways. And then list of synonyms were used to extend the trigger keywords, increasing the number of dependency patterns to 20,494. This run combined the dependency patterns and supervised learning approach while Run1 only used the dependency patterns. The only difference between the latter four runs (Run 2,3,4 and 5) is the threshold for filtering the candidate slot fillers."
SFV2013_02	4	No	NA	NA	NA	NA	Yes	Yes	Yes	Wikipedia	Lucene	InHouse	Stanford	NA	NA	NA	Stanford	Stanford	NA	NA	Patterns	Supervised	NA	NA	InHouseDictionary	"The origin dependency patterns were created through automatic and manual ways. And then list of synonyms were used to extend the trigger keywords, increasing the number of dependency patterns to 20,494. This run combined the dependency patterns and supervised learning approach while Run1 only used the dependency patterns. The only difference between the latter four runs (Run 2,3,4 and 5) is the threshold for filtering the candidate slot fillers."
SFV2013_02	5	No	NA	NA	NA	NA	Yes	Yes	Yes	Wikipedia	Lucene	InHouse	Stanford	NA	NA	NA	Stanford	Stanford	NA	NA	Patterns	Supervised	NA	NA	InHouseDictionary	"The origin dependency patterns were created through automatic and manual ways. And then list of synonyms were used to extend the trigger keywords, increasing the number of dependency patterns to 20,494. This run combined the dependency patterns and supervised learning approach while Run1 only used the dependency patterns. The only difference between the latter four runs (Run 2,3,4 and 5) is the threshold for filtering the candidate slot fillers."
SFV2013_03	1	No	NA	NA	NA	NA	Yes	Yes	No	GoogleAnchors	Lucene	Stanford	Stanford	"Stanford, NELL"	InHouse	NA	Stanford	Stanford	Stanford	Stanford	IE	Supervised	CRF	NA	"NELL, GoogleAnchors, Wikipedia, Freebase"	Plain vanilla run with the configuration that spend the most time under development.
SFV2013_03	2	Yes	NA	NA	NA	NA	Yes	Yes	No	GoogleAnchors	Lucene	Stanford	Stanford	"Stanford, NELL"	Internal heuristics	NA	Stanford	Stanford	Stanford	Stanford	IE	Supervised	CRF	NA	"NELL, GoogleAnchors, Wikipedia, Freebase"	"Alternate configuration using our OpenEval system as a post-validator to improve precision.  OpenEval was trained on the annotations and assessments prior to 2013, but is given access to Google's web search engine to obtain additional information on the fly."
SFV2013_03	3	Yes	NA	NA	NA	NA	Yes	Yes	No	GoogleAnchors	Lucene	Stanford	Stanford	"Stanford, NELL"	Internal heuristics	NA	Stanford	Stanford	Stanford	Stanford	IE	Supervised	CRF	NA	"NELL, GoogleAnchors, Wikipedia, Freebase"	"Alternate to Run 2 using two CRFs, one for PER queries and the other for ORG.  This was a promising alternative, but not one given enough attention to justify being our main run."
SFV2013_04	1	No	NA	NA	NA	NA	Yes	Yes	Yes	InHouse	NA	Lucene	NA	NA	NA	NA	NA	NA	NA	NA	IE	Bootstrapping	NA	NA	NA	Bootstrapping with 1 iteration
SFV2013_04	2	No	NA	NA	NA	NA	Yes	Yes	Yes	InHouse	NA	Lucene	NA	NA	NA	NA	NA	NA	NA	NA	IE	Bootstrapping	NA	NA	NA	Bootstrapping with 2 iterations
SFV2013_04	3	No	NA	NA	NA	NA	Yes	Yes	Yes	InHouse	NA	Lucene	NA	NA	NA	NA	NA	NA	NA	NA	IE	Bootstrapping	NA	NA	NA	Bootstrapping with 3 iterations
SFV2013_05	1	No	NA	below5	3	3	Yes	Yes	No	Wikipedia	Lucene	InHouse	InHouse	"InHouse, Freebase"	NA	NA	NA	NA	NA	NA	Patterns	DistantSupervision	SVM	NA	"Freebase, Wikipedia"	"This is the run using only 'fast' components, this means especially no syntactic analysis and no Wikipedia analysis.  Components used:  SVM DS classifier, Re-weighted (automatic noise reduction scheme) DS surface patterns, manual seed surface patterns, alternate names from Wikipedia link text"
SFV2013_05	2	No	NA	below5	3	3	Yes	Yes	No	Wikipedia	Lucene	InHouse	InHouse	"InHouse, Freebase"	NA	NA	Stanford	Stanford	NA	NA	Patterns	DistantSupervision	NA	NA	"Freebase, Wikipedia"	"Run using only high precision components.  Components are as in run 1, however the SVM classifier has been taken out, and the syntactic patterns have been included."
SFV2013_05	3	No	NA	below5	3	3	Yes	Yes	No	Wikipedia	Lucene	InHouse	InHouse	"InHouse, Freebase"	NA	NA	Stanford	Stanford	NA	NA	Patterns	DistantSupervision	SVM	NA	"Freebase, Wikipedia"	This includes all standard components of our system.  It is a merge of the runs 1 and 2.  Additionally slot fillers extracted from a Wikipedia dump have been used for candidate validation.
SFV2013_05	4	No	NA	below5	3	3	Yes	Yes	No	Wikipedia	Lucene	InHouse	InHouse	"InHouse, Freebase"	NA	NA	Stanford	Stanford	NA	NA	IE	DistantSupervision	SVM	NA	"Freebase, Wikipedia"	"This is a high recall run.  Compared to the other runs with a more recall oriented query matching.  Additionally to using all components as in run 3, per:employee_or_member_of are inferred from predicted per:title slots."
SFV2013_05	5	No	NA	below5	3	3	Yes	Yes	No	Wikipedia	Lucene	InHouse	InHouse	"InHouse, Freebase"	NA	NA	NA	NA	NA	NA	IE	DistantSupervision	SVM	NA	"Freebase, Wikipedia"	"This is a run using shallow components only (i.e. no syntactic analysis), including Slot validation from Slots extracted from Wikipedia."
SFV2013_06	1	No	NA	NA	NA	below5	Yes	Yes	No	NA	Lucene	NA	Stanford	NA	NA	NA	InHouse	TnT	Yamcha	NA	Patterns	Unsupervised	NA	NA	NA	"This is a ""base"" run. It uses an unsupervised relation pattern detection and a classification algorithm that takes into account the slot definitions provided in the guidelines."
SFV2013_06	2	No	NA	NA	NA	below5	Yes	Yes	No	NA	Lucene	NA	Stanford	NA	NA	NA	InHouse	TnT	Yamcha	NA	Patterns	Unsupervised	NA	NA	NA	"It uses an unsupervised relation pattern detection and a classification algorithm that takes into account the slot definitions provided in the guidelines. Run2 is equal to our Run1 for the detection part. For the classification, run2 uses several filters for discarding low evidences and uses a more limited context in the sentence. Thus it generates less slot fillers and a better precision is expected. The contents of run2 are mostly a subset of run1, but not a pruning based on the confidence score but a different parametrization of our system."
SFV2013_06	3	No	NA	NA	NA	below5	Yes	No	No	"Wikipedia, InHouse"	Lucene	NA	Stanford	InHouse	InHouse	NA	NA	InHouse	NA	NA	IE	DistantSupervision	NA	NA	"Wikipedia, WordNet"	Learning patterns for each slot using distant learning from Wikipedia
SFV2013_07	1	No	NA	below5	1	2	Yes	Yes	Yes	Wikipedia	Lucene	NA	InHouse	InHouse	InHouse	NA	Stanford	InHouse	NA	NA	IE	"DistantSupervision, Bootstrapping"	NA	Voting	Freebase	Minimal update to 2012 system to incorporate: confidence model, code for provenance information, and a few additional patterns
SFV2013_08	1	No	NA	below5	below5	1	Yes	Yes	No	Indri	Indri	Indri	Stanford	Stanford	Stanford	NA	Stanford	Stanford	Stanford	NA	Patterns	Bootstrapping	NA	NA	NA	"This run use coreference, rules and some lexions."
SFV2013_08	2	No	NA	below5	below5	1	Yes	Yes	No	Indri	Indri	Indri	Stanford	Stanford	Stanford	NA	Stanford	Stanford	Stanford	NA	Patterns	Bootstrapping	NA	NA	NA	This run use coreference.
SFV2013_08	3	No	NA	below5	below5	1	Yes	Yes	No	Indri	Indri	Indri	Stanford	Stanford	Stanford	NA	Stanford	Stanford	Stanford	NA	Patterns	Bootstrapping	NA	NA	NA	This run use coreference.
SFV2013_08	4	No	NA	below5	below5	1	Yes	Yes	No	Indri	Indri	Indri	Stanford	Stanford	NA	NA	Stanford	Stanford	Stanford	NA	Patterns	Bootstrapping	NA	NA	NA	This run uses dependency patterns to generate fillers and add some rule to get organization's alternate names
SFV2013_08	5	No	NA	below5	below5	1	Yes	Yes	No	Indri	Indri	Indri	Stanford	Stanford	NA	NA	Stanford	Stanford	Stanford	NA	Patterns	Bootstrapping	NA	NA	NA	This run only uses dependency patterns to generate fillers.
SFV2013_09	1	No	5	below5	4	NA	No	Yes	No	NA	Lucene	InHouse	Stanford	Stanford	Stanford	NA	Stanford	Stanford	NA	Stanford	IE	DistantSupervision	MIML	NA	"Gazetteer, Wikipedia, KBP2010, Websnippets, GoogleWikipediaDictionary"	"This run has a basic inference component leveraging, e.g., reflexive relations and sentence-level competition for which entities participate in an extracted relation. Slot fills were retrieved from the 2010 and 2013 source docs as well as Wikipedia (July download). Slots which did not have any justification in the initial sentences were re-queried in the 2013 source docs, and the best provenance was found our of these sentences."
SFV2013_09	2	No	5	below5	4	NA	No	Yes	No	NA	Lucene	InHouse	Stanford	NA	Stanford	NA	Stanford	Stanford	NA	Stanford	IE	DistantSupervision	MIML	NA	"Gazetteer, Wikipedia, KBP2010, Websnippets, GoogleWikipediaDictionary"	"This run does not include the basic inference from Run1, and uses only MIML-RE and hand-coded rules. Slot fills were retrieved from the 2010 and 2013 source docs as well as Wikipedia (July download). Slots which did not have any justification in the initial sentences were re-queried in the 2013 source docs, and the best provenance was found our of these sentences."
SFV2013_09	3	No	5	below5	4	NA	No	Yes	No	NA	Lucene	InHouse	Stanford	Stanford	Stanford	ReVerb	Stanford	Stanford	NA	Stanford	IE	DistantSupervision	MIML	NA	"Gazetteer, Wikipedia, KBP2010, Websnippets, GoogleWikipediaDictionary"	"This run has longer-range inference rules, and incorporates inference rules over ReVerb extractions as well. Slot fills were retrieved from the 2010 and 2013 source docs as well as Wikipedia (July download). Slots which did not have any justification in the initial sentences were re-queried in the 2013 source docs, and the best provenance was found our of these sentences."
SFV2013_09	4	No	5	below5	4	NA	No	Yes	No	NA	Lucene	InHouse	Stanford	Stanford	Stanford	NA	Stanford	Stanford	NA	Stanford	IE	DistantSupervision	MIML	NA	"Gazetteer, Wikipedia, KBP2010, Websnippets, GoogleWikipediaDictionary"	"This run has no hand-coded rules or sophisticated inference (including geographic inferences from the Gazetteer), relying entirely on MIML-RE for relation extraction. Slot fills were retrieved from the 2010 and 2013 source docs as well as Wikipedia (July download). Slots which did not have any justification in the initial sentences were re-queried in the 2013 source docs, and the best provenance was found our of these sentences."
SFV2013_09	5	No	5	below5	4	NA	Yes	Yes	No	NA	Lucene	InHouse	Stanford	Stanford	Stanford	NA	Stanford	Stanford	NA	Stanford	IE	DistantSupervision	MIML	NA	"Gazetteer, Wikipedia, KBP2010, Websnippets, GoogleWikipediaDictionary"	"This run is identical to our expected best system Run1 (basic inference, sentence level competition), but using only the 2013 source docs and not making use of either Wikipedia or the 2010 source docs at test time."
SFV2013_10	1	No	NA	2	2	NA	Yes	Yes	Yes	NA	Terrier	NA	Stanford	NA	NA	NA	NA	Stanford	NA	NA	IE 	Supervised	NaiveBayes	NA	NA	identifies boundary POS tags to extract candidate slot fillers
SFV2013_10	2	No	NA	2	2	NA	Yes	Yes	Yes	NA	Terrier	NA	Stanford	NA	NA	NA	NA	Stanford	NA	NA	IE 	Supervised	NA	NA	NA	identifies a candidate slot boundary using the lemma from of each token to extract candidate slot fillers  
SFV2013_10	3	No	NA	2	2	NA	Yes	No	No	NA	Terrier	NA	Stanford	NA	NA	NA	NA	Stanford	NA	NA	Patterns	NA	NA	NA	NA	combining pattern matching and event detection techniques to extract candidate slot fillers.
SFV2013_11	1	No	NA	NA	below5	NA	Yes	Yes	No	NA	InHouse	InHouse	Stanford	Stanford	Stanford	TARSQI	Stanford	Stanford	Stanford	NA	IE	DistantSupervision	NA	NA	Freebase	This run aggregates evidence for a filler across multiple examples.
SFV2013_11	2	No	NA	NA	below5	NA	Yes	Yes	No	NA	InHouse	InHouse	Stanford	Stanford	Stanford	TARSQI	Stanford	Stanford	Stanford	NA	IE	DistantSupervision	NA	NA	Freebase	This run does not aggregate scores across multiple examples.
SFV2013_12	1	No	NA	NA	NA	NA	Yes	Yes	Yes	NA	Lucene	Lucene	Stanford	NA	NA	NA	MaltParser	Stanford	Stanford	NA	IE	DistantSupervision	LogisticRegression	NA	Wikipedia	This is our current best run that passes validation.
SFV2013_13	1	No	NA	NA	NA	NA	Yes	Yes	No	NA	Galago	NA	NA	Factorie	Factorie	NattyDateParser	Factorie	Factorie	NA	NA	"UniversalSchema, Patterns"	"Supervised, Unsupervised"	MatrixFactorization	NA	"Wikipedia, Freebase, FactorieDictionary"	This is our sole run.
SFV2013_14	1	No	NA	NA	NA	NA	Yes	Yes	No	KBP-TK	Lucene	"Stanford, KBP-TK"	"Stanford, KBP-TK"	"Stanford, KBP-TK"	"Stanford, KBP-TK"	NA	"Stanford, KBP-TK"	"Stanford, KBP-TK"	KBP-TK	NA	"IE, QA, Patterns"	NA	NA	NA	NA	"This is the KBP TK baseline + inference run, there is some filtering based on the combination of results, but it is mostly a merge and much less sophisticated then we were planning.  Next time..."
SFV2013_14	2	No	NA	NA	NA	NA	Yes	Yes	No	KBP-TK	KBP-TK	KBP-TK	KBP-TK	KBP-TK	KBP-TK	KBP-TK	KBP-TK	KBP-TK	KBP-TK	NA	"IE, QA"	NA	NA	NA	NA	This is the KBP TK baseline
SFV2013_14	3	No	NA	NA	NA	NA	Yes	No	No	KBP-TK	Lucene	Stanford	Stanford	Stanford	Stanford	Stanford	KBP-TK	Stanford	Stanford	NA	"Patterns, LogicalInference"	NA	NA	NA	NA	This is the logic-based inference component that works mostly from CoreNLP input.  The KBPTK document retrieval front end is used to cut down on the size of the corpus to analyze.  We only focused on a small number of person slots.
SFV2013_15	1	No	NA	3	NA	NA	Yes	Yes	No	"Wikipedia, InHouse"	Lucene	InHouse	KBP-TK	InHouse	KBP-TK	CunyBlender	Stanford	NA	NA	NA	"Patterns, Constraints"	Unsupervised	NA	Ranking	"Freebase, YAGO, DBPedia, Wikipedia "	Full System.
SFV2013_15	2	No	NA	3	NA	NA	Yes	Yes	No	"Wikipedia, InHouse"	Lucene	InHouse	KBP-TK	InHouse	KBP-TK	CunyBlender	Stanford	NA	NA	NA	"Patterns, Constraints"	Unsupervised	NA	Ranking	"Freebase, YAGO, DBPedia, Wikipedia "	Full system without using alternative name answers for query expansion
SFV2013_15	3	No	NA	3	NA	NA	Yes	Yes	No	"Wikipedia, InHouse"	Lucene	InHouse	KBP-TK	InHouse	KBP-TK	CunyBlender	Stanford	NA	NA	NA	"Patterns, Constraints"	Unsupervised	NA	Ranking	"Freebase, YAGO, DBPedia, Wikipedia "	Full system without using alternative names for query expansion.  Offsets formatting issue partially fixed.
SFV2013_15	4	No	NA	3	NA	NA	Yes	Yes	No	"Wikipedia, InHouse"	Lucene	InHouse	KBP-TK	InHouse	KBP-TK	CunyBlender	Stanford	NA	NA	NA	"Patterns, Constraints"	Unsupervised	NA	Ranking	"Freebase, YAGO, DBPedia, Wikipedia "	Full system without using entity coreference resolution.
SFV2013_15	5	No	NA	3	NA	NA	Yes	Yes	No	"Wikipedia, InHouse"	Lucene	InHouse	KBP-TK	InHouse	KBP-TK	CunyBlender	Stanford	NA	NA	NA	"Patterns, Constraints"	Unsupervised	NA	Ranking	"Freebase, YAGO, DBPedia, Wikipedia "	Full system with pattern path length constraints (length <=8; which is the standard used by previous top teams)
SFV2013_16	1	No	NA	NA	NA	NA	Yes	No	No	NA	NA	NA	InHouse	InHouse	InHouse	InHouse	InHouse	InHouse	InHouse	InHouse	Patterns	NA	NA	NA	InHouseCorpus	"Our approach is a rule-based method applied to the result of the semantic parser ABBYY Compreno analysis. ABBYY Compreno contains a semantic hierarchy of more than 100000 concepts and uses both statistical and rule-based methods in order to construct a labeled constituent structure. Our rules are templates of labeled constituent trees, which allow us to extract entities and facts, given the result of ABBYY Compreno text analysis. Facts are complex situational frames such as Occupation or Birth, which may have several attributes (e. g. position, employer and employee for Occupation). The last step of slot filling is mapping the facts onto slots."
SFV2013_17	1	No	NA	NA	NA	NA	Yes	Yes	Yes	NA	NA	NA	NA	NA	NA	CunyBlender	NA	NA	NA	NA	"LogicalInference, ProbInference"	Supervised	BLP	NA	DBpedia for rule and weight learning only	"This run includes inferences made using our Bayesian Logic Programming Textual Inference system, which learns probabilistic logical rules and weights to combine multiple sources of evidence to generate new inferred relation instances.  Input to this run was the BLENDER 1.5 extractions."
SFV2013_17	2	No	NA	NA	NA	NA	Yes	Yes	Yes	NA	NA	NA	NA	NA	NA	CunyBlender	NA	NA	NA	NA	NA	NA	NA	NA	DBPedia	"This run includes a baseline performance based on extractions only, and does not have the additional inferences provided in Run1."
SFV2013_18	1	No	NA	NA	NA	NA	Yes	Yes	NA	InHouse	InHouse	InHouse	NA	NA	NA	NA	Stanford	Stanford	NA	NA	Patterns	InHouse	NA	NA	NA	"This RUN has a special feature that it uses the minimum of the NLP tools to arrive at Text Semantics as grammatical constituents without the need to exploit other NLP tools like Anaphora Resolver, NER, NP chunker, etc.  This RUN aims itself for generating subjective answer keys in QA domain.  "
